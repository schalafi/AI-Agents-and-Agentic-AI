{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install litellm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from dotenv import load_dotenv \n",
        "\n",
        "# Load .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Access the key \n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "8ad29cf6-8e41-4172-9c5f-47c68ddbaa2c"
      },
      "outputs": [],
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Response\n",
        "- using the gpt-4o-mini \n",
        "\n",
        "Certainly! Here's a function in Python that swaps the keys and values in a dictionary. This function assumes that the values in the original dictionary are unique and can be used as keys in the new dictionary.\n",
        "\n",
        "```python\n",
        "def swap_dict(original_dict):\n",
        "    # Use a dictionary comprehension to swap keys and values\n",
        "    swapped_dict = {value: key for key, value in original_dict.items()}\n",
        "    return swapped_dict\n",
        "\n",
        "# Example usage:\n",
        "example_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "swapped = swap_dict(example_dict)\n",
        "print(swapped)  # Output: {1: 'a', 2: 'b', 3: 'c'}\n",
        "```\n",
        "\n",
        "### How it works:\n",
        "- The function `swap_dict` takes a single argument, `original_dict`.\n",
        "- It uses a dictionary comprehension to create a new dictionary where each value from the original dictionary becomes a key and each key becomes the corresponding value.\n",
        "- Finally, it returns the new swapped dictionary.\n",
        "\n",
        "### Note:\n",
        "If there are duplicate values in the original dictionary, the last key will overwrite any previous keys in the swapped dictionary. If dealing with non-unique values is a requirement, you might need to accumulate keys in a list for each value. Let me know if you’d like to see that implementation!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_responseb64(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024,\n",
        "        response_format = { \"type\": \"json_object\" } \n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary. The output should be in  b64_json format\"}\n",
        "]\n",
        "response = generate_responseb64(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from litellm import completion, get_supported_openai_params\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict\n",
        "\n",
        "class SwapResponse(BaseModel):\n",
        "    swapped_function: str\n",
        "\n",
        "def generate_responseb64(messages: List[Dict]) -> str:\n",
        "    supported = get_supported_openai_params(model=\"openai/gpt-4o-mini\")\n",
        "    assert \"response_format\" in supported, \"Model doesn’t support response_format\"\n",
        "\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024,\n",
        "        response_format=SwapResponse\n",
        "    )\n",
        "    return response.choices[0].message.content  # content is validated via Pydantic\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming. Respond in JSON fitting the schema.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
        "]\n",
        "\n",
        "print(generate_responseb64(messages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "supported = get_supported_openai_params(model=\"openai/gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "supported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
